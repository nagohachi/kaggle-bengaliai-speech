{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e314822",
   "metadata": {
    "papermill": {
     "duration": 0.01035,
     "end_time": "2023-08-24T07:44:57.569823",
     "exception": false,
     "start_time": "2023-08-24T07:44:57.559473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reference\n",
    "\n",
    "Firstly, Please upvote/refer to [@tawara's](https://www.kaggle.com/ttahara) discussions and inference [notebook](https://www.kaggle.com/code/ttahara/bengali-sr-public-wav2vec2-0-w-lm-baseline).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "53316a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ON_KAGGLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac4e38d",
   "metadata": {
    "papermill": {
     "duration": 0.009193,
     "end_time": "2023-08-24T07:44:57.608004",
     "exception": false,
     "start_time": "2023-08-24T07:44:57.598811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1ec1b474",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-08-24T07:44:57.629653Z",
     "iopub.status.busy": "2023-08-24T07:44:57.628858Z",
     "iopub.status.idle": "2023-08-24T07:46:11.766211Z",
     "shell.execute_reply": "2023-08-24T07:46:11.765003Z"
    },
    "papermill": {
     "duration": 74.151024,
     "end_time": "2023-08-24T07:46:11.768695",
     "exception": false,
     "start_time": "2023-08-24T07:44:57.617671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if ON_KAGGLE:\n",
    "    import os\n",
    "    os.system(\"!cp -r ../input/python-packagess2 ./\")\n",
    "    os.system(\"!tar xvfz ./python-packagess2/jiwer.tgz\")\n",
    "    os.system(\"!pip install ./jiwer/jiwer-2.3.0-py3-none-any.whl -f ./ --no-index\")\n",
    "    os.system(\"!tar xvfz ./python-packagess2/normalizer.tgz\")\n",
    "    os.system(\"!pip install ./normalizer/bnunicodenormalizer-0.0.24.tar.gz -f ./ --no-index\")\n",
    "    os.system(\"!tar xvfz ./python-packagess2/pyctcdecode.tgz\")\n",
    "    os.system(\"!pip install ./pyctcdecode/attrs-22.1.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\")\n",
    "    os.system(\"!pip install ./pyctcdecode/exceptiongroup-1.0.0rc9-py3-none-any.whl -f ./ --no-index --no-deps\")\n",
    "    os.system(\"!pip install ./pyctcdecode/hypothesis-6.54.4-py3-none-any.whl -f ./ --no-index --no-deps\")\n",
    "    os.system(\"!pip install ./pyctcdecode/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl -f ./ --no-index --no-deps\")\n",
    "    os.system(\"!pip install ./pyctcdecode/pygtrie-2.5.0.tar.gz -f ./ --no-index --no-deps\")\n",
    "    os.system(\"!pip install ./pyctcdecode/sortedcontainers-2.4.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\")\n",
    "    os.system(\"!pip install ./pyctcdecode/pyctcdecode-0.4.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\")\n",
    "    os.system(\"!tar xvfz ./python-packagess2/pypikenlm.tgz\")\n",
    "    os.system(\"!pip install ./pypikenlm/pypi-kenlm-0.1.20220713.tar.gz -f ./ --no-index --no-deps]\")\n",
    "    os.system(\"rm -r python-packagess2 jiwer normalizer pyctcdecode pypikenlm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c1f12eda",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-24T07:46:12.789133Z",
     "iopub.status.busy": "2023-08-24T07:46:12.788484Z",
     "iopub.status.idle": "2023-08-24T07:46:25.308949Z",
     "shell.execute_reply": "2023-08-24T07:46:25.308079Z"
    },
    "papermill": {
     "duration": 12.537845,
     "end_time": "2023-08-24T07:46:25.311315",
     "exception": false,
     "start_time": "2023-08-24T07:46:12.773470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import pandas as pd\n",
    "import pyctcdecode\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import librosa\n",
    "\n",
    "import pyctcdecode\n",
    "import kenlm\n",
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ProcessorWithLM, Wav2Vec2ForCTC\n",
    "from bnunicodenormalizer import Normalizer\n",
    "\n",
    "import cloudpickle as cpkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4e7213fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T07:46:25.341476Z",
     "iopub.status.busy": "2023-08-24T07:46:25.340459Z",
     "iopub.status.idle": "2023-08-24T07:46:25.346666Z",
     "shell.execute_reply": "2023-08-24T07:46:25.345643Z"
    },
    "papermill": {
     "duration": 0.023671,
     "end_time": "2023-08-24T07:46:25.348831",
     "exception": false,
     "start_time": "2023-08-24T07:46:25.325160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition\n"
     ]
    }
   ],
   "source": [
    "ROOT = Path.cwd().parent\n",
    "print(ROOT)\n",
    "INPUT = ROOT / \"input\"\n",
    "DATA = INPUT / \"bengaliai-speech\"\n",
    "TRAIN = DATA / \"train_mp3s\"\n",
    "TEST = DATA / \"test_mp3s\"\n",
    "\n",
    "SAMPLING_RATE = 16_000\n",
    "MODEL_PATH = INPUT / \"bengali-wav2vec2-finetuned/\"\n",
    "LM_PATH = INPUT / \"bengali-sr-download-public-trained-models/wav2vec2-xls-r-300m-bengali/language_model/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e71699b",
   "metadata": {
    "papermill": {
     "duration": 0.014742,
     "end_time": "2023-08-24T07:46:25.377081",
     "exception": false,
     "start_time": "2023-08-24T07:46:25.362339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### load model, processor, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "804af9fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T07:46:25.405703Z",
     "iopub.status.busy": "2023-08-24T07:46:25.405350Z",
     "iopub.status.idle": "2023-08-24T07:46:43.393658Z",
     "shell.execute_reply": "2023-08-24T07:46:43.392694Z"
    },
    "papermill": {
     "duration": 18.005617,
     "end_time": "2023-08-24T07:46:43.396146",
     "exception": false,
     "start_time": "2023-08-24T07:46:25.390529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at /home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/input/bengali-wav2vec2-finetuned and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_PATH)\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "333c6dab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T07:46:43.425744Z",
     "iopub.status.busy": "2023-08-24T07:46:43.425384Z",
     "iopub.status.idle": "2023-08-24T07:47:24.752281Z",
     "shell.execute_reply": "2023-08-24T07:47:24.751327Z"
    },
    "papermill": {
     "duration": 41.356708,
     "end_time": "2023-08-24T07:47:24.766948",
     "exception": false,
     "start_time": "2023-08-24T07:46:43.410240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unigrams not provided and cannot be automatically determined from LM file (only arpa format). Decoding accuracy might be reduced.\n",
      "Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?\n",
      "No known unigrams provided, decoding results might be a lot worse.\n"
     ]
    }
   ],
   "source": [
    "vocab_dict = processor.tokenizer.get_vocab()\n",
    "sorted_vocab_dict = {k: v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}\n",
    "\n",
    "decoder = pyctcdecode.build_ctcdecoder(\n",
    "    list(sorted_vocab_dict.keys()),\n",
    "    str(LM_PATH / \"5gram.bin\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "790c3741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T07:47:24.796209Z",
     "iopub.status.busy": "2023-08-24T07:47:24.795866Z",
     "iopub.status.idle": "2023-08-24T07:47:24.801748Z",
     "shell.execute_reply": "2023-08-24T07:47:24.800863Z"
    },
    "papermill": {
     "duration": 0.023402,
     "end_time": "2023-08-24T07:47:24.804208",
     "exception": false,
     "start_time": "2023-08-24T07:47:24.780806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "processor_with_lm = Wav2Vec2ProcessorWithLM(\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    decoder=decoder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf49bae9",
   "metadata": {
    "papermill": {
     "duration": 0.014205,
     "end_time": "2023-08-24T07:47:24.832810",
     "exception": false,
     "start_time": "2023-08-24T07:47:24.818605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "667fe7a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T07:47:24.862321Z",
     "iopub.status.busy": "2023-08-24T07:47:24.861943Z",
     "iopub.status.idle": "2023-08-24T07:47:24.868686Z",
     "shell.execute_reply": "2023-08-24T07:47:24.867699Z"
    },
    "papermill": {
     "duration": 0.023623,
     "end_time": "2023-08-24T07:47:24.870779",
     "exception": false,
     "start_time": "2023-08-24T07:47:24.847156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BengaliSRTestDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        audio_paths: list[str],\n",
    "        sampling_rate: int\n",
    "    ):\n",
    "        self.audio_paths = audio_paths\n",
    "        self.sampling_rate = sampling_rate\n",
    "        \n",
    "    def __len__(self,):\n",
    "        return len(self.audio_paths)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        audio_path = self.audio_paths[index]\n",
    "        sr = self.sampling_rate\n",
    "        # audio_path にある .mp3 ファイルを、PCEN を用いて前処理\n",
    "        y1, s3 = librosa.load(audio_path, sr=sr, mono=False)\n",
    "        S1 = librosa.feature.melspectrogram(y=y1, sr=sr, n_mels=128)\n",
    "        D1 = librosa.power_to_db(S1, ref=np.max)\n",
    "        Dp1 = librosa.pcen(S1 * (2**31), sr=sr, hop_length=512, gain=1.1, bias=2, power=0.25, time_constant=0.8, eps=1e-06, max_size=2)\n",
    "\n",
    "        return Dp1\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        audio_path = self.audio_paths[index]\n",
    "        sr = self.sampling_rate\n",
    "        w = librosa.load(audio_path, sr=sr, mono=False)[0]\n",
    "        # 例: メルスペクトログラムの計算\n",
    "        S = librosa.feature.melspectrogram(y=w, sr=sr, n_mels=128)\n",
    "        print(S.shape)\n",
    "        return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "284b0108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T07:47:24.899393Z",
     "iopub.status.busy": "2023-08-24T07:47:24.899045Z",
     "iopub.status.idle": "2023-08-24T07:47:24.926187Z",
     "shell.execute_reply": "2023-08-24T07:47:24.924945Z"
    },
    "papermill": {
     "duration": 0.044021,
     "end_time": "2023-08-24T07:47:24.928489",
     "exception": false,
     "start_time": "2023-08-24T07:47:24.884468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id                                           sentence\n",
      "0  0f3dac00655e  এছাড়াও নিউজিল্যান্ড এ ক্রিকেট দলের হয়েও খেলছ...\n",
      "1  a9395e01ad21  এছাড়াও নিউজিল্যান্ড এ ক্রিকেট দলের হয়েও খেলছ...\n",
      "2  bf36ea8b718d  এছাড়াও নিউজিল্যান্ড এ ক্রিকেট দলের হয়েও খেলছ...\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(DATA / \"sample_submission.csv\", dtype={\"id\": str})\n",
    "print(test.head())\n",
    "\n",
    "test_audio_paths = [str(TEST / f\"{aid}.mp3\") for aid in test[\"id\"].values]\n",
    "\n",
    "test_dataset = BengaliSRTestDataset(\n",
    "    test_audio_paths, SAMPLING_RATE\n",
    ")\n",
    "\n",
    "collate_func = partial(\n",
    "    processor_with_lm.feature_extractor,\n",
    "    return_tensors=\"pt\", sampling_rate=SAMPLING_RATE,\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=8, shuffle=False,\n",
    "    num_workers=2, collate_fn=collate_func, drop_last=False,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "395e38f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA / \"train.csv\", dtype={\"id\": str}).drop([\"split\"], axis=1)\n",
    "# train からランダムに 100 個選ぶ\n",
    "train_random_100 = train.sample(100, random_state=42)\n",
    "train_audio_paths_random_100 = [str(TRAIN / f\"{aid}.mp3\") for aid in train_random_100[\"id\"].values]\n",
    "\n",
    "train_dataset_random_100 = BengaliSRTestDataset(\n",
    "    train_audio_paths_random_100, SAMPLING_RATE\n",
    ")\n",
    "\n",
    "train_loader_random_100 = torch.utils.data.DataLoader(\n",
    "    train_dataset_random_100, batch_size=8, shuffle=False,\n",
    "    num_workers=2, collate_fn=collate_func, drop_last=False,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2a5b5c",
   "metadata": {
    "papermill": {
     "duration": 0.013823,
     "end_time": "2023-08-24T07:47:25.030256",
     "exception": false,
     "start_time": "2023-08-24T07:47:25.016433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "da7dcabe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T07:47:25.059784Z",
     "iopub.status.busy": "2023-08-24T07:47:25.059440Z",
     "iopub.status.idle": "2023-08-24T07:47:25.135027Z",
     "shell.execute_reply": "2023-08-24T07:47:25.134108Z"
    },
    "papermill": {
     "duration": 0.093011,
     "end_time": "2023-08-24T07:47:25.137299",
     "exception": false,
     "start_time": "2023-08-24T07:47:25.044288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a8bb863b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T07:47:25.166875Z",
     "iopub.status.busy": "2023-08-24T07:47:25.166529Z",
     "iopub.status.idle": "2023-08-24T07:47:30.405043Z",
     "shell.execute_reply": "2023-08-24T07:47:30.404048Z"
    },
    "papermill": {
     "duration": 5.256093,
     "end_time": "2023-08-24T07:47:30.407537",
     "exception": false,
     "start_time": "2023-08-24T07:47:25.151444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model = model.eval()\n",
    "# model = model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f230da4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T07:47:30.436509Z",
     "iopub.status.busy": "2023-08-24T07:47:30.436132Z",
     "iopub.status.idle": "2023-08-24T07:47:46.252443Z",
     "shell.execute_reply": "2023-08-24T07:47:46.251367Z"
    },
    "papermill": {
     "duration": 15.833532,
     "end_time": "2023-08-24T07:47:46.254872",
     "exception": false,
     "start_time": "2023-08-24T07:47:30.421340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7f2baa77c24de8bf08a6f38c7b6dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fad619b75b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/nago/.pyenv/versions/3.10.12/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fad619b75b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fad619b75b0>    \n",
      "if w.is_alive():Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "  File \"/home/nago/.pyenv/versions/3.10.12/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'self._shutdown_workers()\n",
      "\n",
      "AssertionError  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      ": can only test a child process    \n",
      "if w.is_alive():\n",
      "  File \"/home/nago/.pyenv/versions/3.10.12/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7fad619b75b0>assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "Traceback (most recent call last):\n",
      "AssertionError  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      ": can only test a child process    \n",
      "self._shutdown_workers()\n",
      "Exception ignored in:   File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fad619b75b0>\n",
      "    Traceback (most recent call last):\n",
      "if w.is_alive():  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "\n",
      "      File \"/home/nago/.pyenv/versions/3.10.12/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "self._shutdown_workers()    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "\n",
      "    AssertionErrorif w.is_alive():: \n",
      "can only test a child process  File \"/home/nago/.pyenv/versions/3.10.12/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "Exception ignored in: AssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x7fad619b75b0>: \n",
      "can only test a child processTraceback (most recent call last):\n",
      "  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "\n",
      "    self._shutdown_workers()Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fad619b75b0>  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "\n",
      "Traceback (most recent call last):\n",
      "      File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "if w.is_alive():\n",
      "      File \"/home/nago/.pyenv/versions/3.10.12/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "self._shutdown_workers()    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "\n",
      "AssertionError    : if w.is_alive():can only test a child process\n",
      "\n",
      "  File \"/home/nago/.pyenv/versions/3.10.12/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fad619b75b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/nago/.pyenv/versions/3.10.12/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 173)\n",
      "(128, 178)(128, 182)\n",
      "\n",
      "(128, 116)\n",
      "(128, 46)(128, 24)\n",
      "\n",
      "(128, 102)(128, 69)\n",
      "\n",
      "(128, 60)(128, 92)\n",
      "\n",
      "(128, 60)(128, 150)\n",
      "\n",
      "(128, 62)(128, 119)\n",
      "\n",
      "(128, 128)(128, 310)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:167: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.asarray(value, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:167: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.asarray(value, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 145)\n",
      "(128, 154)(128, 169)\n",
      "\n",
      "(128, 57)\n",
      "(128, 158)\n",
      "(128, 68)\n",
      "(128, 34)\n",
      "(128, 83)\n",
      "(128, 220)\n",
      "(128, 51)(128, 131)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/transformers/feature_extraction_utils.py\", line 175, in convert_to_tensors\n    tensor = as_tensor(value)\n  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/transformers/feature_extraction_utils.py\", line 167, in as_tensor\n    return np.asarray(value, dtype=dtype)\nValueError: could not broadcast input array from shape (128,173) into shape (128,)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py\", line 199, in __call__\n    padded_inputs = self.pad(\n  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/transformers/feature_extraction_sequence_utils.py\", line 224, in pad\n    return BatchFeature(batch_outputs, tensor_type=return_tensors)\n  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/transformers/feature_extraction_utils.py\", line 78, in __init__\n    self.convert_to_tensors(tensor_type=tensor_type)\n  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/transformers/feature_extraction_utils.py\", line 181, in convert_to_tensors\n    raise ValueError(\nValueError: Unable to create tensor, you should probably activate padding with 'padding=True' to have batched tensors with the same length.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m pred_sentence_list \u001b[39m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 4\u001b[0m     \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(train_loader_random_100)):\n\u001b[1;32m      5\u001b[0m         x \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39minput_values\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m         x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/tqdm/notebook.py:249\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[0;32m--> 249\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    250\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    251\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m    252\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m~/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1373\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/transformers/feature_extraction_utils.py\", line 175, in convert_to_tensors\n    tensor = as_tensor(value)\n  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/transformers/feature_extraction_utils.py\", line 167, in as_tensor\n    return np.asarray(value, dtype=dtype)\nValueError: could not broadcast input array from shape (128,173) into shape (128,)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py\", line 199, in __call__\n    padded_inputs = self.pad(\n  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/transformers/feature_extraction_sequence_utils.py\", line 224, in pad\n    return BatchFeature(batch_outputs, tensor_type=return_tensors)\n  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/transformers/feature_extraction_utils.py\", line 78, in __init__\n    self.convert_to_tensors(tensor_type=tensor_type)\n  File \"/home/nago/Documents/ML/kaggle-Bengali.AI_Speech-Recognition/.venv/lib/python3.10/site-packages/transformers/feature_extraction_utils.py\", line 181, in convert_to_tensors\n    raise ValueError(\nValueError: Unable to create tensor, you should probably activate padding with 'padding=True' to have batched tensors with the same length.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(128, 51)(128, 51)\n",
      "\n",
      "(128, 141)(128, 223)\n",
      "\n",
      "(128, 184)(128, 119)\n",
      "\n",
      "(128, 74)\n",
      "(128, 242)\n",
      "(128, 165)\n",
      "(128, 128)\n",
      "(128, 174)\n",
      "(128, 242)\n",
      "(128, 150)\n"
     ]
    }
   ],
   "source": [
    "pred_sentence_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm(train_loader_random_100)):\n",
    "        x = batch[\"input_values\"]\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        with torch.cuda.amp.autocast(True):\n",
    "            y = model(x).logits\n",
    "        y = y.detach().cpu().numpy()\n",
    "        \n",
    "        for l in y:  \n",
    "            sentence = processor_with_lm.decode(l, beam_width=512).text\n",
    "            pred_sentence_list.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4371bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_sentence_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea630735",
   "metadata": {
    "papermill": {
     "duration": 0.01351,
     "end_time": "2023-08-24T07:47:46.282751",
     "exception": false,
     "start_time": "2023-08-24T07:47:46.269241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b5437",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T07:47:46.312071Z",
     "iopub.status.busy": "2023-08-24T07:47:46.311709Z",
     "iopub.status.idle": "2023-08-24T07:47:46.318568Z",
     "shell.execute_reply": "2023-08-24T07:47:46.317560Z"
    },
    "papermill": {
     "duration": 0.024321,
     "end_time": "2023-08-24T07:47:46.320867",
     "exception": false,
     "start_time": "2023-08-24T07:47:46.296546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bnorm = Normalizer()\n",
    "\n",
    "def postprocess(sentence):\n",
    "    period_set = set([\".\", \"?\", \"!\", \"।\"])\n",
    "    _words = [bnorm(word)['normalized']  for word in sentence.split()]\n",
    "    sentence = \" \".join([word for word in _words if word is not None])\n",
    "    try:\n",
    "        if sentence[-1] not in period_set:\n",
    "            sentence+=\"।\"\n",
    "    except:\n",
    "        # print(sentence)\n",
    "        sentence = \"।\"\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df2e715",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T07:47:46.350821Z",
     "iopub.status.busy": "2023-08-24T07:47:46.350477Z",
     "iopub.status.idle": "2023-08-24T07:47:46.387786Z",
     "shell.execute_reply": "2023-08-24T07:47:46.386870Z"
    },
    "papermill": {
     "duration": 0.054748,
     "end_time": "2023-08-24T07:47:46.389722",
     "exception": false,
     "start_time": "2023-08-24T07:47:46.334974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e03805ed9a94adbac7a7a38ed812212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pp_pred_sentence_list = [\n",
    "    postprocess(s) for s in tqdm(pred_sentence_list)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85480853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T07:47:46.420380Z",
     "iopub.status.busy": "2023-08-24T07:47:46.418745Z",
     "iopub.status.idle": "2023-08-24T07:47:46.431963Z",
     "shell.execute_reply": "2023-08-24T07:47:46.430941Z"
    },
    "papermill": {
     "duration": 0.030629,
     "end_time": "2023-08-24T07:47:46.434331",
     "exception": false,
     "start_time": "2023-08-24T07:47:46.403702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  id                                           sentence  \\\n",
      "834672  ddaf142d0c90  বিকেলেও তাঁর কথায় পরিষ্কার বোঝা যাচ্ছিল, তাসক...   \n",
      "23712   06410684a9cf  শেরেবাংলা স্টেডিয়ামের গেট, একাডেমি মাঠ এমনকি ম...   \n",
      "138570  24e75fb9e453  ম্যানেজার সাহেব আগ্রহভরে রেলের উপর ঝুঁকিয়া নৌক...   \n",
      "514425  8897e9274541  যে ব্যক্তির রাজনৈতিক দল বেশি ভোট পাবে তিনিই হব...   \n",
      "631655  a7afd30d7a4a  এটিই তার খেলোয়াড়ী জীবনের স্বর্ণালী মুহুর্ত ছিল।   \n",
      "\n",
      "                                                sentence2  \n",
      "834672  বিকেলেও তাঁর কথায় পুরস্কার বোঝা যাচ্ছিল তাসকিন...  \n",
      "23712   সে বাংলা স্টেডিয়ামের কেট একাডেমির মাঠে এমনকি ম...  \n",
      "138570                                                  ।  \n",
      "514425                                       রাজনৈতিক বা।  \n",
      "631655                   এটিই তার খেলাটি জীবন সনায়ভূতছিল।  \n"
     ]
    }
   ],
   "source": [
    "train_compare = train_random_100.copy()\n",
    "train_compare[\"sentence2\"] = pp_pred_sentence_list\n",
    "\n",
    "print(train_compare.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e20c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321ecbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_wer(solution, submission):\n",
    "    sum_wer = 0\n",
    "    for s, t in zip(solution, submission):\n",
    "        sum_wer += jiwer.wer(s, t)\n",
    "    return sum_wer / len(solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d34db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5080396547896546"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_wer(train_compare[\"sentence\"], train_compare[\"sentence2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e7c7b4",
   "metadata": {
    "papermill": {
     "duration": 0.013785,
     "end_time": "2023-08-24T07:47:46.463068",
     "exception": false,
     "start_time": "2023-08-24T07:47:46.449283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## EOF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 182.89233,
   "end_time": "2023-08-24T07:47:49.858262",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-24T07:44:46.965932",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "13d8e9a2b3ba49cb8c4327dc9f641d07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2bae7d8649b24152b85af5367508198c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3b6b1f5d28ef4d2c99f3b5ad44779beb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8f3e0a5a84b54e388f96bc61b487f8cd",
       "placeholder": "​",
       "style": "IPY_MODEL_13d8e9a2b3ba49cb8c4327dc9f641d07",
       "value": "100%"
      }
     },
     "4646153df1ab47f8bee4ddb65fd6a3cf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "474e69c17ec143c6b49c454444285089": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "52bc6f6d99a141ae94eb4f55751e1a4f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_474e69c17ec143c6b49c454444285089",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d3f050a3d2134e909c706369f9cb897a",
       "value": 1
      }
     },
     "5a5d48ba42ed43f186a50fe14fd2b9f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3b6b1f5d28ef4d2c99f3b5ad44779beb",
        "IPY_MODEL_52bc6f6d99a141ae94eb4f55751e1a4f",
        "IPY_MODEL_68fc84ae22cc4f2a8869a030231d16aa"
       ],
       "layout": "IPY_MODEL_f72452f9f0ef499ab5eb98fdaf32d84d"
      }
     },
     "5a7ee2cbc4a54da1bff0012725705c4a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "65ae1e0ed93d41c6ba5572cbdb91007f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "68fc84ae22cc4f2a8869a030231d16aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_75d0359e4b3d47b194524669126588d5",
       "placeholder": "​",
       "style": "IPY_MODEL_72de19d3de704659baf4b11c5759b8f6",
       "value": " 1/1 [00:15&lt;00:00, 15.71s/it]"
      }
     },
     "72de19d3de704659baf4b11c5759b8f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "75d0359e4b3d47b194524669126588d5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83790777dc484745b0b063462ac6ddbb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "852a79ebcf304e1ba8672edf3676c7d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8f3e0a5a84b54e388f96bc61b487f8cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b53216984c845d1bb3505b3ec0e66dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ed4cd02fb0474187b56d9f354228c4de",
        "IPY_MODEL_c2c81e3c47a844f69b7caa018169ae29",
        "IPY_MODEL_fce3a42fa5ec4927b20d897ca05cfc6f"
       ],
       "layout": "IPY_MODEL_5a7ee2cbc4a54da1bff0012725705c4a"
      }
     },
     "bd691a8af99343938555b461159c3d98": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c2c81e3c47a844f69b7caa018169ae29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4646153df1ab47f8bee4ddb65fd6a3cf",
       "max": 3,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_83790777dc484745b0b063462ac6ddbb",
       "value": 3
      }
     },
     "d3f050a3d2134e909c706369f9cb897a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ed4cd02fb0474187b56d9f354228c4de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bd691a8af99343938555b461159c3d98",
       "placeholder": "​",
       "style": "IPY_MODEL_65ae1e0ed93d41c6ba5572cbdb91007f",
       "value": "100%"
      }
     },
     "f72452f9f0ef499ab5eb98fdaf32d84d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fce3a42fa5ec4927b20d897ca05cfc6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2bae7d8649b24152b85af5367508198c",
       "placeholder": "​",
       "style": "IPY_MODEL_852a79ebcf304e1ba8672edf3676c7d5",
       "value": " 3/3 [00:00&lt;00:00, 97.81it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
