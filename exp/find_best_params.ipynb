{"cells":[{"cell_type":"markdown","metadata":{},"source":["#### Reference\n","\n","Firstly, Please upvote/refer to [@snnclsr](https://www.kaggle.com/snnclsr) discussions and inference [notebook]https://www.kaggle.com/code/snnclsr/0-444-optimize-decoding-parameters-with-optuna).\n","\n","\n","Third, please upvote this one :)"]},{"cell_type":"markdown","metadata":{},"source":["## What this notebook features??\n","\n","- I wanted to showcase the impact of finetuning the models on competition dataset.\n","- Current version comprises of finetuned model only with 10% of competition training data.\n","- I will publish the training code in upcoming days. You can refer to this [dataset]()\n","\n","Public models from hugging faces:\n","* `https://huggingface.co/ai4bharat/indicwav2vec_v1_bengali` for Wav2vec2CTC Model only\n","* `https://huggingface.co/arijitx/wav2vec2-xls-r-300m-bengali` for Language Model\n","\n","I didn't trained these models using the competitaion data at all. I just want to know public models score as baseline.  \n","\n","So we may get higher and higher score by fine-tuning on competition data.\n","\n","**Note: I only finetuned the indicwav2vec_v1_bengali which is a CTC model. I am still using the public LM model mentioned above.**\n","\n","\n","### Everything above PLUS\n","\n","- How to find the best decoding params using optuna on valid dataset.\n","\n","It's being suggested by the authors of the [pyctcdecode](https://github.com/kensho-technologies/pyctcdecode/tree/main) developers that we should perform a parameter search because it can improve our results on a specific tasks other than English such as ours.\n","\n","> (Note: pyctcdecode contains several free hyperparameters that can strongly influence error rate and wall time. Default values for these parameters were (merely) chosen in order to yield good performance for one particular use case. For best results, especially when working with languages other than English, users are encouraged to perform a hyperparameter optimization study on their own data.)\n","\n","So we will give it a try to find the best parameters in the validation split of the train dataset (because of the time constraints we will only use 5k). Here are the list of decoding params for easy access:\n","\n","```python\n","# from: https://github.com/kensho-technologies/pyctcdecode/blob/main/pyctcdecode/constants.py\n","# default parameters for decoding (can be modified)\n","DEFAULT_ALPHA = 0.515\n","DEFAULT_BETA = 1.665\n","DEFAULT_UNK_LOGP_OFFSET = -10.0\n","DEFAULT_BEAM_WIDTH = 100\n","DEFAULT_HOTWORD_WEIGHT = 10.0\n","DEFAULT_PRUNE_LOGP = -10.0\n","DEFAULT_PRUNE_BEAMS = False\n","DEFAULT_MIN_TOKEN_LOGP = -5.0\n","DEFAULT_SCORE_LM_BOUNDARY = True\n","\n","# other constants for decoding\n","AVG_TOKEN_LEN = 6  # average number of characters expected per token (used for UNK scoring)\n","MIN_TOKEN_CLIP_P = 1e-15  # clipping to avoid underflow in case of malformed logit input\n","LOG_BASE_CHANGE_FACTOR = 1.0 / math.log10(math.e)  # kenlm returns base10 but we like natural\n","```"]},{"cell_type":"markdown","metadata":{},"source":["## Import"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-09-12T20:07:46.033128Z","iopub.status.busy":"2023-09-12T20:07:46.032807Z","iopub.status.idle":"2023-09-12T20:08:58.826621Z","shell.execute_reply":"2023-09-12T20:08:58.825449Z","shell.execute_reply.started":"2023-09-12T20:07:46.033101Z"},"trusted":true},"outputs":[],"source":["# !cp -r ../input/python-packages2 ./\n","\n","# !tar xvfz ./python-packages2/jiwer.tgz\n","# !pip install ./jiwer/jiwer-2.3.0-py3-none-any.whl -f ./ --no-index\n","# !tar xvfz ./python-packages2/normalizer.tgz\n","# !pip install ./normalizer/bnunicodenormalizer-0.0.24.tar.gz -f ./ --no-index\n","# !tar xvfz ./python-packages2/pyctcdecode.tgz\n","# !pip install ./pyctcdecode/attrs-22.1.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n","# !pip install ./pyctcdecode/exceptiongroup-1.0.0rc9-py3-none-any.whl -f ./ --no-index --no-deps\n","# !pip install ./pyctcdecode/hypothesis-6.54.4-py3-none-any.whl -f ./ --no-index --no-deps\n","# !pip install ./pyctcdecode/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl -f ./ --no-index --no-deps\n","# !pip install ./pyctcdecode/pygtrie-2.5.0.tar.gz -f ./ --no-index --no-deps\n","# !pip install ./pyctcdecode/sortedcontainers-2.4.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n","# !pip install ./pyctcdecode/pyctcdecode-0.4.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n","\n","# !tar xvfz ./python-packages2/pypikenlm.tgz\n","# !pip install ./pypikenlm/pypi-kenlm-0.1.20220713.tar.gz -f ./ --no-index --no-deps"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T20:08:58.829819Z","iopub.status.busy":"2023-09-12T20:08:58.829417Z","iopub.status.idle":"2023-09-12T20:09:30.21527Z","shell.execute_reply":"2023-09-12T20:09:30.214065Z","shell.execute_reply.started":"2023-09-12T20:08:58.829783Z"},"trusted":true},"outputs":[],"source":["# !pip install ../input/jiwer-3-0-3/jiwer-3.0.3-py3-none-any.whl"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T20:09:30.217751Z","iopub.status.busy":"2023-09-12T20:09:30.217357Z","iopub.status.idle":"2023-09-12T20:09:31.166558Z","shell.execute_reply":"2023-09-12T20:09:31.165242Z","shell.execute_reply.started":"2023-09-12T20:09:30.217717Z"},"trusted":true},"outputs":[],"source":["# rm -r python-packages2 jiwer normalizer pyctcdecode pypikenlm"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-12T20:09:31.170639Z","iopub.status.busy":"2023-09-12T20:09:31.170241Z","iopub.status.idle":"2023-09-12T20:09:43.52614Z","shell.execute_reply":"2023-09-12T20:09:43.525173Z","shell.execute_reply.started":"2023-09-12T20:09:31.170608Z"},"trusted":true},"outputs":[],"source":["import typing as tp\n","from pathlib import Path\n","from functools import partial\n","from dataclasses import dataclass, field\n","\n","import pandas as pd\n","import pyctcdecode\n","import numpy as np\n","from tqdm.notebook import tqdm\n","\n","import librosa\n","\n","import pyctcdecode\n","import kenlm\n","import torch\n","from transformers import Wav2Vec2Processor, Wav2Vec2ProcessorWithLM, Wav2Vec2ForCTC\n","from bnunicodenormalizer import Normalizer\n","\n","import cloudpickle as cpkl"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T20:09:43.527971Z","iopub.status.busy":"2023-09-12T20:09:43.527633Z","iopub.status.idle":"2023-09-12T20:09:43.536593Z","shell.execute_reply":"2023-09-12T20:09:43.535536Z","shell.execute_reply.started":"2023-09-12T20:09:43.527937Z"},"trusted":true},"outputs":[],"source":["FIND_PARAMS = True\n","\n","ROOT = Path.cwd().parent\n","INPUT = ROOT / \"input\"\n","DATA = INPUT / \"bengaliai-speech\"\n","TRAIN = DATA / \"train_mp3s\"\n","TEST = DATA / \"test_mp3s\"\n","\n","SAMPLING_RATE = 16_000\n","MODEL_PATH = INPUT / INPUT / \"saved_model-finetune-with-commonvoice-without-unigram/ensemble/\"\n","LM_PATH = INPUT / \"arijitx-full-model/wav2vec2-xls-r-300m-bengali/language_model/\""]},{"cell_type":"markdown","metadata":{},"source":["### load model, processor, decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T20:09:43.538399Z","iopub.status.busy":"2023-09-12T20:09:43.537872Z","iopub.status.idle":"2023-09-12T20:09:57.944506Z","shell.execute_reply":"2023-09-12T20:09:57.943547Z","shell.execute_reply.started":"2023-09-12T20:09:43.538364Z"},"trusted":true},"outputs":[],"source":["model = Wav2Vec2ForCTC.from_pretrained(MODEL_PATH)\n","processor = Wav2Vec2Processor.from_pretrained(MODEL_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T20:09:57.946416Z","iopub.status.busy":"2023-09-12T20:09:57.94599Z","iopub.status.idle":"2023-09-12T20:10:39.791321Z","shell.execute_reply":"2023-09-12T20:10:39.790285Z","shell.execute_reply.started":"2023-09-12T20:09:57.946383Z"},"trusted":true},"outputs":[],"source":["vocab_dict = processor.tokenizer.get_vocab()\n","sorted_vocab_dict = {k: v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}\n","\n","decoder = pyctcdecode.build_ctcdecoder(\n","    list(sorted_vocab_dict.keys()),\n","    str(LM_PATH / \"5gram.bin\"),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T20:10:39.793838Z","iopub.status.busy":"2023-09-12T20:10:39.793114Z","iopub.status.idle":"2023-09-12T20:10:39.801395Z","shell.execute_reply":"2023-09-12T20:10:39.800375Z","shell.execute_reply.started":"2023-09-12T20:10:39.793777Z"},"trusted":true},"outputs":[],"source":["processor_with_lm = Wav2Vec2ProcessorWithLM(\n","    feature_extractor=processor.feature_extractor,\n","    tokenizer=processor.tokenizer,\n","    decoder=decoder\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## prepare dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T20:10:39.803329Z","iopub.status.busy":"2023-09-12T20:10:39.80289Z","iopub.status.idle":"2023-09-12T20:10:39.813786Z","shell.execute_reply":"2023-09-12T20:10:39.812693Z","shell.execute_reply.started":"2023-09-12T20:10:39.803298Z"},"trusted":true},"outputs":[],"source":["class BengaliSRTestDataset(torch.utils.data.Dataset):\n","    \n","    def __init__(\n","        self,\n","        audio_paths: list[str],\n","        sampling_rate: int\n","    ):\n","        self.audio_paths = audio_paths\n","        self.sampling_rate = sampling_rate\n","        \n","    def __len__(self,):\n","        return len(self.audio_paths)\n","    \n","    def __getitem__(self, index: int):\n","        audio_path = self.audio_paths[index]\n","        sr = self.sampling_rate\n","        w = librosa.load(audio_path, sr=sr, mono=False)[0]\n","        \n","        return w"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T20:10:39.818438Z","iopub.status.busy":"2023-09-12T20:10:39.817925Z","iopub.status.idle":"2023-09-12T20:10:45.383677Z","shell.execute_reply":"2023-09-12T20:10:45.382535Z","shell.execute_reply.started":"2023-09-12T20:10:39.818406Z"},"trusted":true},"outputs":[],"source":["if not torch.cuda.is_available():\n","    device = torch.device(\"cpu\")\n","else:\n","    device = torch.device(\"cuda\")\n","\n","model = model.to(device)\n","model = model.eval()\n","model = model.half()"]},{"cell_type":"markdown","metadata":{},"source":["# Finding the best decoding params"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T20:10:45.385975Z","iopub.status.busy":"2023-09-12T20:10:45.385511Z","iopub.status.idle":"2023-09-12T20:10:45.474626Z","shell.execute_reply":"2023-09-12T20:10:45.473623Z","shell.execute_reply.started":"2023-09-12T20:10:45.385934Z"},"trusted":true},"outputs":[],"source":["import jiwer\n","\n","bnorm = Normalizer()\n","\n","def postprocess(sentence):\n","    period_set = set([\".\", \"?\", \"!\", \"ред\"])\n","    _words = [bnorm(word)['normalized']  for word in sentence.split()]\n","    sentence = \" \".join([word for word in _words if word is not None])\n","    try:\n","        if sentence[-1] not in period_set:\n","            sentence+=\"ред\"\n","    except:\n","        sentence = \"ред\"\n","    return sentence\n","\n","\n","def score(gts, preds):\n","    return jiwer.wer(gts, preds)\n","\n","\n","def inference(m, data_loader):\n","    logits = []\n","    with torch.no_grad():\n","        for batch in tqdm(data_loader):\n","            x = batch[\"input_values\"]\n","            x = x.to(device, non_blocking=True)\n","            with torch.cuda.amp.autocast(True):\n","                y = model(x).logits\n","            y = y.detach().cpu().numpy()\n","            logits.extend(y)\n","    return logits\n","\n","\n","def decode(logits, params={\"beam_width\": 2000}, pp=True):    \n","    pred_sentence_list = [processor_with_lm.decode(sentence, **params).text for sentence in tqdm(logits)]\n","    if pp:\n","        pred_sentence_list = [postprocess(s) for s in pred_sentence_list]\n","    return pred_sentence_list"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T20:10:45.476468Z","iopub.status.busy":"2023-09-12T20:10:45.476029Z","iopub.status.idle":"2023-09-12T20:10:45.482016Z","shell.execute_reply":"2023-09-12T20:10:45.481104Z","shell.execute_reply.started":"2023-09-12T20:10:45.476426Z"},"trusted":true},"outputs":[],"source":["constants = \"\"\"\n","# from: https://github.com/kensho-technologies/pyctcdecode/blob/main/pyctcdecode/constants.py\n","# default parameters for decoding (can be modified)\n","DEFAULT_ALPHA = 0.495\n","DEFAULT_BETA = 1.275\n","DEFAULT_UNK_LOGP_OFFSET = -10.0\n","DEFAULT_BEAM_WIDTH = 100\n","DEFAULT_HOTWORD_WEIGHT = 10.0\n","DEFAULT_PRUNE_LOGP = -10.0\n","DEFAULT_PRUNE_BEAMS = False\n","DEFAULT_MIN_TOKEN_LOGP = -5.0\n","DEFAULT_SCORE_LM_BOUNDARY = True\n","\n","# other constants for decoding\n","AVG_TOKEN_LEN = 6  # average number of characters expected per token (used for UNK scoring)\n","MIN_TOKEN_CLIP_P = 1e-15  # clipping to avoid underflow in case of malformed logit input\n","LOG_BASE_CHANGE_FACTOR = 1.0 / math.log10(math.e)  # kenlm returns base10 but we like natural\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T20:10:45.484277Z","iopub.status.busy":"2023-09-12T20:10:45.483358Z","iopub.status.idle":"2023-09-12T20:10:45.495962Z","shell.execute_reply":"2023-09-12T20:10:45.495057Z","shell.execute_reply.started":"2023-09-12T20:10:45.484238Z"},"trusted":true},"outputs":[],"source":["def objective(trial):\n","    \"\"\"\n","    alpha: weight for language model during shallow fusion\n","    beta: weight for length score adjustment of during scoring\n","    unk_score_offset: amount of log score offset for unknown tokens\n","    lm_score_boundary: whether to have kenlm respect boundaries when scoring\n","    \"\"\"\n","    alpha = trial.suggest_float(\"alpha\", 0.0, 2.15)\n","    beta = trial.suggest_float(\"beta\", 0.0, 2.05)\n","    beam_width = trial.suggest_categorical(\"beam_width\", [2000,])\n","    gts = valid[\"sentence\"].values.tolist()\n","    decode_params = {\n","        \"alpha\": alpha,\n","        \"beta\": beta,\n","        \"beam_width\": beam_width\n","    }\n","    preds = decode(logits, params=decode_params, pp=True)\n","    wer_score = score(gts, preds)\n","    return wer_score"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T20:10:45.49817Z","iopub.status.busy":"2023-09-12T20:10:45.497293Z","iopub.status.idle":"2023-09-12T20:10:45.512523Z","shell.execute_reply":"2023-09-12T20:10:45.511355Z","shell.execute_reply.started":"2023-09-12T20:10:45.498136Z"},"trusted":true},"outputs":[],"source":["# Default decoding configuration in the public notebook.\n","best_params = {\"beam_width\": 2000}\n","\n","if FIND_PARAMS:\n","    import optuna\n","    from optuna.trial import TrialState\n","    \n","    # valid = pd.read_csv(DATA / \"excluded_valid.csv\") # dtype={\"id\": str}\n","    # valid_audio_paths = [str(TRAIN / f\"{aid}.mp3\") for aid in valid[\"id\"].values]\n","    valid = pd.read_csv(DATA / \"train.csv\") # dtype={\"id\": str}\n","    valid = valid[valid[\"split\"] == \"valid\"]\n","    valid_audio_paths = [str(TRAIN / f\"{aid}.mp3\") for aid in valid[\"id\"].values]\n","\n","    valid_dataset = BengaliSRTestDataset(\n","        valid_audio_paths, SAMPLING_RATE\n","    )\n","\n","    collate_func = partial(\n","        processor_with_lm.feature_extractor,\n","        return_tensors=\"pt\", sampling_rate=SAMPLING_RATE,\n","        padding=True,\n","    )\n","\n","    valid_loader = torch.utils.data.DataLoader(\n","        valid_dataset, batch_size=16, shuffle=False,\n","        num_workers=2, collate_fn=collate_func, drop_last=False,\n","        pin_memory=True,\n","    )\n","    # Calculating the base score\n","    print(constants)\n","    logits = inference(model, valid_loader)\n","    base_preds = decode(logits)\n","    gts = valid[\"sentence\"].values.tolist()\n","    base_wer_score = score(gts, base_preds)\n","    print(f\"Base wer score: {base_wer_score}\")\n","\n","    study = optuna.create_study(direction=\"minimize\")\n","    study.optimize(objective, n_trials=200)\n","\n","    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n","    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n","\n","    print(\"Study statistics: \")\n","    print(\"  Number of finished trials: \", len(study.trials))\n","    print(\"  Number of pruned trials: \", len(pruned_trials))\n","    print(\"  Number of complete trials: \", len(complete_trials))\n","\n","    print(\"Best trial:\")\n","    trial = study.best_trial\n","\n","    print(\"  Value: \", trial.value)\n","\n","    print(\"  Params: \")\n","    for key, value in trial.params.items():\n","        print(\"    {}: {}\".format(key, value))\n","    \n","    if study.best_value < base_wer_score:\n","        print(f\"Base score improved to {study.best_value} from {base_wer_score}. Assigning {study.best_params} to best_params\")\n","        best_params = study.best_params"]},{"cell_type":"markdown","metadata":{},"source":["# Inference with the best params"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T20:10:45.514433Z","iopub.status.busy":"2023-09-12T20:10:45.513898Z","iopub.status.idle":"2023-09-12T20:10:45.527589Z","shell.execute_reply":"2023-09-12T20:10:45.526613Z","shell.execute_reply.started":"2023-09-12T20:10:45.514403Z"},"trusted":true},"outputs":[],"source":["# Please see the Version 3. of this notebook to see the results.\n","# best_params = {'alpha': 0.345, 'beta': 0.06, 'beam_width': 768}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T20:10:45.52929Z","iopub.status.busy":"2023-09-12T20:10:45.528851Z","iopub.status.idle":"2023-09-12T20:10:45.538701Z","shell.execute_reply":"2023-09-12T20:10:45.537553Z","shell.execute_reply.started":"2023-09-12T20:10:45.529259Z"},"trusted":true},"outputs":[],"source":["print(f\"Running the inference with params: {best_params}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T20:10:45.540679Z","iopub.status.busy":"2023-09-12T20:10:45.540221Z","iopub.status.idle":"2023-09-12T20:11:01.110759Z","shell.execute_reply":"2023-09-12T20:11:01.109676Z","shell.execute_reply.started":"2023-09-12T20:10:45.540647Z"},"trusted":true},"outputs":[],"source":["# test = pd.read_csv(DATA / \"sample_submission.csv\", dtype={\"id\": str})\n","# test_audio_paths = [str(TEST / f\"{aid}.mp3\") for aid in test[\"id\"].values]\n","\n","# test_dataset = BengaliSRTestDataset(\n","#     test_audio_paths, SAMPLING_RATE\n","# )\n","# collate_func = partial(\n","#     processor_with_lm.feature_extractor,\n","#     return_tensors=\"pt\", sampling_rate=SAMPLING_RATE,\n","#     padding=True,\n","# )\n","# test_loader = torch.utils.data.DataLoader(\n","#     test_dataset, batch_size=8, shuffle=False,\n","#     num_workers=2, collate_fn=collate_func, drop_last=False,\n","#     pin_memory=True,\n","# )\n","\n","# pred_sentence_list = []\n","\n","# with torch.no_grad():\n","#     for batch in tqdm(test_loader):\n","#         x = batch[\"input_values\"]\n","#         x = x.to(device, non_blocking=True)\n","#         with torch.cuda.amp.autocast(True):\n","#             y = model(x).logits\n","#         y = y.detach().cpu().numpy()\n","        \n","#         for l in y:  \n","#             sentence = processor_with_lm.decode(l, **best_params).text\n","#             pred_sentence_list.append(sentence)\n","\n","\n","# pp_pred_sentence_list = [postprocess(s) for s in tqdm(pred_sentence_list)]"]},{"cell_type":"markdown","metadata":{},"source":["## Make Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-12T20:11:01.11324Z","iopub.status.busy":"2023-09-12T20:11:01.112593Z","iopub.status.idle":"2023-09-12T20:11:01.130296Z","shell.execute_reply":"2023-09-12T20:11:01.129137Z","shell.execute_reply.started":"2023-09-12T20:11:01.113202Z"},"trusted":true},"outputs":[],"source":["# test[\"sentence\"] = pp_pred_sentence_list\n","# test.to_csv(\"submission.csv\", index=False)\n","# print(test.head())"]},{"cell_type":"markdown","metadata":{},"source":["## EOF"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
